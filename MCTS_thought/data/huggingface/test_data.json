{"id": "39733337", "seed": 30724, "n_tools": 1, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}], "sampled_links": [], "user_request": "Please help me classify the content of the given audio file 'example.wav'.", "task_steps": ["Step 1: Classify the audio file to identify its content."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}], "task_links": [], "type": "single"}
{"id": "57328119", "seed": 311465, "n_tools": 1, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I need a conversational response for the following question: 'What are the benefits of exercising regularly?'", "task_steps": ["Step 1: Use the Conversational tool to generate a relevant and coherent response based on the given text prompt."], "task_nodes": [{"task": "Conversational", "arguments": ["What are the benefits of exercising regularly?"]}], "task_links": [], "type": "single"}
{"id": "21059734", "seed": 910735, "n_tools": 1, "sampled_nodes": [{"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [], "user_request": "Please convert the following text to an audio file: 'The quick brown fox jumps over the lazy dog.'", "task_steps": ["Step 1: Use Text-to-Speech tool to convert the given text to audio"], "task_nodes": [{"task": "Text-to-Speech", "arguments": ["The quick brown fox jumps over the lazy dog."]}], "task_links": [], "type": "single"}
{"id": "26876996", "seed": 482774, "n_tools": 6, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}], "sampled_links": [{"source": "Text-to-Speech", "target": "Audio-to-Audio"}, {"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Text Generation"}, {"source": "Text Generation", "target": "Document Question Answering"}, {"source": "Document Question Answering", "target": "Text-to-Video"}], "user_request": "Create a video summarizing example.jpg document image about the topic 'environmental protection' and enhance the speech quality of the narration", "task_steps": ["Step 1: Generate text related to a given topic", "Step 2: Answer questions about a document image", "Step 3: Convert text answer to speech", "Step 4: Enhance the produced speech audio", "Step 5: Transcribe the enhanced speech to text", "Step 6: Generate a video based on the transcribed text"], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["<node-4>"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-0>"]}, {"task": "Document Question Answering", "arguments": ["example.jpg", "<node-3>"]}, {"task": "Text Generation", "arguments": ["environmental protection"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}, {"task": "Text-to-Video", "arguments": ["<node-1>"]}], "task_links": [{"source": "Text-to-Speech", "target": "Audio-to-Audio"}, {"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Text Generation"}, {"source": "Text Generation", "target": "Document Question Answering"}, {"source": "Document Question Answering", "target": "Text-to-Video"}], "type": "chain"}
{"id": "12072486", "seed": 990787, "n_tools": 3, "sampled_nodes": [{"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Segmentation", "target": "Image Classification"}, {"source": "Image Classification", "target": "Question Answering"}], "user_request": "I have an image named 'example.jpg', which contains different objects. Please help me segment these objects, label them, and answer questions based on the provided text: 'What is the most commonly found object in households? An object commonly found in households is a chair.'", "task_steps": ["Step 1: Segment the example.jpg image into different objects using Image Segmentation.", "Step 2: Perform Image Classification to label the segmented objects in the image.", "Step 3: Retrieve answers from user-provided text using Question Answering."], "task_nodes": [{"task": "Image Segmentation", "arguments": ["example.jpg"]}, {"task": "Image Classification", "arguments": ["<node-0>"]}, {"task": "Question Answering", "arguments": ["What is the most commonly found object in households?", "An object commonly found in households is a chair."]}], "task_links": [{"source": "Image Segmentation", "target": "Image Classification"}, {"source": "Image Classification", "target": "Question Answering"}], "type": "chain"}
{"id": "30039881", "seed": 753823, "n_tools": 6, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Image Editing"}, {"source": "Depth Estimation", "target": "Visual Question Answering"}, {"source": "Image Editing", "target": "Depth Estimation"}, {"source": "Visual Question Answering", "target": "Text-to-Video"}], "user_request": "I have a noisy audio recording 'example.wav' and I would like to enhance the audio and separate the sources, transcribe the enhanced audio into text, and then use that text to modify an image 'example.jpg' accordingly. Once the image is modified, I want to estimate the depth of the objects in the image. Then, I have a question 'What is the color of the main object in the modified image?'. Answer this question and generate a video 'example.mp4' based on the answer.", "task_steps": ["Step 1: Enhance audio and separate sources using Audio-to-Audio tool", "Step 2: Transcribe enhanced audio to text using Automatic Speech Recognition", "Step 3: Edit an image based on transcribed text using Image Editing", "Step 4: Estimate depth from the edited image using Depth Estimation", "Step 5: Answer a question about the edited image using Visual Question Answering", "Step 6: Generate a video based on the answer from Visual Question Answering using Text-to-Video"], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["example.wav"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-0>"]}, {"task": "Depth Estimation", "arguments": ["<node-3>"]}, {"task": "Image Editing", "arguments": ["<node-1>", "example.jpg"]}, {"task": "Text-to-Video", "arguments": ["<node-5>"]}, {"task": "Visual Question Answering", "arguments": ["<node-2>", "What is the color of the main object in the modified image?"]}], "task_links": [{"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Image Editing"}, {"source": "Depth Estimation", "target": "Visual Question Answering"}, {"source": "Image Editing", "target": "Depth Estimation"}, {"source": "Visual Question Answering", "target": "Text-to-Video"}], "type": "chain"}
{"id": "23050366", "seed": 515007, "n_tools": 1, "sampled_nodes": [{"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have an image 'example.jpg' that contains text. Please convert this image into text.", "task_steps": ["Convert the image 'example.jpg' into text."], "task_nodes": [{"task": "Image-to-Text", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "27629751", "seed": 467897, "n_tools": 3, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Question Answering", "target": "Text Generation"}, {"source": "Text Generation", "target": "Conversational"}], "user_request": "I have a long article about the history and benefits of meditation. I would like to know the best time to meditate according to the article and have a conversation and paraphrasing of the response.", "task_steps": ["Step 1: Use the 'Question Answering' tool to find a specific piece of information from a given text.", "Step 2: Generate a conversational response using the 'Conversational' tool based on the output of the 'Question Answering' tool.", "Step 3: Use the 'Text Generation' tool to create a paraphrased version of the conversational response from Step 2."], "task_nodes": [{"task": "Conversational", "arguments": ["<node-2>"]}, {"task": "Question Answering", "arguments": ["I have a long article about the history and benefits of meditation. I would like to know the best time to meditate according to the article and have a conversation and paraphrasing of the response.", "What is the best time to meditate according to the article?"]}, {"task": "Text Generation", "arguments": ["<node-1>"]}], "task_links": [{"source": "Question Answering", "target": "Text Generation"}, {"source": "Text Generation", "target": "Conversational"}], "type": "chain"}
{"id": "95856870", "seed": 76665, "n_tools": 1, "sampled_nodes": [{"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have an image named 'example.jpg', and I want to know which class the image belongs to according to an image classification model.", "task_steps": ["Step 1: Classify the image to determine its class"], "task_nodes": [{"task": "Image Classification", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "19046865", "seed": 469954, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Visual Question Answering"}, {"source": "Text Generation", "target": "Token Classification"}, {"source": "Visual Question Answering", "target": "Text Generation"}], "user_request": "I have a voice recording 'example.wav' and an image 'example.jpg'. Can you first detect the emotion of the narrator from the audio, then answer the question 'How may this person feel in this scene?' based on the image and detected emotion. After that, generate a brief text describing the answer, and finally, identify the named entities and part-of-speech in the text.", "task_steps": ["1. Classify the audio to get emotion information.", "2. Answer a question based on the image and emotion information.", "3. Generate a text description based on the answer.", "4. Perform token classification on the generated text."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Text Generation", "arguments": ["<node-3>"]}, {"task": "Token Classification", "arguments": ["<node-1>"]}, {"task": "Visual Question Answering", "arguments": ["example.jpg", "<node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Visual Question Answering"}, {"source": "Text Generation", "target": "Token Classification"}, {"source": "Visual Question Answering", "target": "Text Generation"}], "type": "chain"}
{"id": "19900733", "seed": 310540, "n_tools": 1, "sampled_nodes": [{"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have a long text document about climate change, and I need a summarized version of it to present to my colleagues. Text: 'Climate change is a long-term alteration in the global climate patterns, affecting a wide array of ecosystems and human activities. The primary cause of climate change is the increase in greenhouse gas emissions primarily due to human activities such as burning fossil fuels, deforestation, and industrial processes. Climate change has resulted in rising temperatures and fluctuating weather patterns, leading to devastating natural disasters such as floods, heatwaves, and droughts. To mitigate the impacts of climate change, it is essential to adopt measures like reducing greenhouse gas emissions, shifting to renewable energy sources, and conserving forests and other natural resources.' Please provide a summarized version of this text.", "task_steps": ["Step 1: Summarize the given text using the Summarization tool."], "task_nodes": [{"task": "Summarization", "arguments": ["Climate change is a long-term alteration in the global climate patterns, affecting a wide array of ecosystems and human activities. The primary cause of climate change is the increase in greenhouse gas emissions primarily due to human activities such as burning fossil fuels, deforestation, and industrial processes. Climate change has resulted in rising temperatures and fluctuating weather patterns, leading to devastating natural disasters such as floods, heatwaves, and droughts. To mitigate the impacts of climate change, it is essential to adopt measures like reducing greenhouse gas emissions, shifting to renewable energy sources, and conserving forests and other natural resources."]}], "task_links": [], "type": "single"}
{"id": "22303666", "seed": 70766, "n_tools": 5, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Conversational"}, {"source": "Image-to-Text", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}], "user_request": "I have this image file 'example.jpg' containing text. I need to extract the text, convert it to speech, enhance the speech quality, transcribe it back to text, and generate a conversational response.", "task_steps": ["1. Extract text from the given image.", "2. Convert the extracted text to speech.", "3. Enhance the quality of the generated speech audio.", "4. Transcribe the enhanced speech audio back to text.", "5. Generate a conversational response to the transcribed text."], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["<node-4>"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-0>"]}, {"task": "Conversational", "arguments": ["<node-1>"]}, {"task": "Image-to-Text", "arguments": ["example.jpg"]}, {"task": "Text-to-Speech", "arguments": ["<node-3>"]}], "task_links": [{"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Conversational"}, {"source": "Image-to-Text", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}], "type": "chain"}
{"id": "28661386", "seed": 5317, "n_tools": 1, "sampled_nodes": [{"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have a user-specified text about the history of computer science and a question related to the text. Text: 'The history of computer science began long before the modern discipline of computer science. Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi, which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. The first known computer algorithm was written by Ada Lovelace in 1842, for use with Charles Babbage's analytical engine. The first electronic computer, known as the ENIAC, was completed in 1945.' Question: 'Who wrote the first known computer algorithm?'", "task_steps": ["Step 1: Provide a user-specified text and a question related to the text"], "task_nodes": [{"task": "Question Answering", "arguments": ["The history of computer science began long before the modern discipline of computer science. Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi, which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. The first known computer algorithm was written by Ada Lovelace in 1842, for use with Charles Babbage's analytical engine. The first electronic computer, known as the ENIAC, was completed in 1945.", "Who wrote the first known computer algorithm?"]}], "task_links": [], "type": "single"}
{"id": "11096083", "seed": 872502, "n_tools": 1, "sampled_nodes": [{"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have a text in Spanish: 'Hola, \u00bfc\u00f3mo est\u00e1s?'. Please translate it into English.", "task_steps": ["Step 1: Translate a given text from one language to another."], "task_nodes": [{"task": "Translation", "arguments": ["Hola, \u00bfc\u00f3mo est\u00e1s?"]}], "task_links": [], "type": "single"}
{"id": "27078880", "seed": 815143, "n_tools": 7, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Document Question Answering", "target": "Text Generation"}, {"source": "Image-to-Image", "target": "Tabular Classification"}, {"source": "Question Answering", "target": "Text-to-Speech"}, {"source": "Summarization", "target": "Question Answering"}, {"source": "Tabular Classification", "target": "Document Question Answering"}, {"source": "Text Generation", "target": "Summarization"}], "user_request": "Use the table data in example.jpg and answer the question 'What is the total revenue in Q2?'. Summarize the information, then answer 'What is the main takeaway of the summary?' and convert the answer into an audio file.", "task_steps": ["Step 1: Transform the input image using Image-to-Image", "Step 2: Classify the table in the transformed image using Tabular Classification", "Step 3: Use the Document Question Answering model to answer a question based on the table", "Step 4: Generate text using the Text Generation model based on the answer from the previous step", "Step 5: Create a summary of the generated text using Summarization model", "Step 6: Answer a user question about the summary using the Question Answering model", "Step 7: Turn the answer to the user question into speech using Text-to-Speech"], "task_nodes": [{"task": "Document Question Answering", "arguments": ["<node-4>", "What is the total revenue in Q2?"]}, {"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Question Answering", "arguments": ["<node-3>", "What is the main takeaway of the summary?"]}, {"task": "Summarization", "arguments": ["<node-5>"]}, {"task": "Tabular Classification", "arguments": ["<node-1>"]}, {"task": "Text Generation", "arguments": ["<node-0>"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}], "task_links": [{"source": "Document Question Answering", "target": "Text Generation"}, {"source": "Image-to-Image", "target": "Tabular Classification"}, {"source": "Question Answering", "target": "Text-to-Speech"}, {"source": "Summarization", "target": "Question Answering"}, {"source": "Tabular Classification", "target": "Document Question Answering"}, {"source": "Text Generation", "target": "Summarization"}], "type": "chain"}
{"id": "33225296", "seed": 197908, "n_tools": 4, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Document Question Answering", "target": "Text-to-Speech"}, {"source": "Image Editing", "target": "Document Question Answering"}, {"source": "Image Segmentation", "target": "Image Editing"}], "user_request": "I have an image (example.jpg) of a document containing both text and diagrams. I want to change the color of one of the diagrams as described in this text: 'Change the color of the circle in the diagram to blue.' Then I have a question about the document: 'What is the title of the document?' Please provide me with an audio answer (example.wav).", "task_steps": ["Step 1: Perform Image Segmentation on the given image", "Step 2: Edit the segmented image based on the given text description", "Step 3: Perform Document Question Answering on the edited image with the provided question", "Step 4: Convert the answer from Document Question Answering into speech using Text-to-Speech"], "task_nodes": [{"task": "Document Question Answering", "arguments": ["<node-1>", "What is the title of the document?"]}, {"task": "Image Editing", "arguments": ["Change the color of the circle in the diagram to blue.", "<node-2>"]}, {"task": "Image Segmentation", "arguments": ["example.jpg"]}, {"task": "Text-to-Speech", "arguments": ["<node-0>"]}], "task_links": [{"source": "Document Question Answering", "target": "Text-to-Speech"}, {"source": "Image Editing", "target": "Document Question Answering"}, {"source": "Image Segmentation", "target": "Image Editing"}], "type": "chain"}
{"id": "12271360", "seed": 14403, "n_tools": 3, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Segmentation", "target": "Object Detection"}, {"source": "Object Detection", "target": "Document Question Answering"}], "user_request": "I have a document image 'example.jpg' and I want to detect and recognize the objects in the image. After that, I'd like to get the answer to the following question: 'What is the main topic of the document?'.", "task_steps": ["Step 1: Segment the image into regions using Image Segmentation.", "Step 2: Detect objects in the segmented image using Object Detection.", "Step 3: Answer a question about the document based on the detected objects using Document Question Answering."], "task_nodes": [{"task": "Image Segmentation", "arguments": ["example.jpg"]}, {"task": "Object Detection", "arguments": ["<node-1>"]}, {"task": "Document Question Answering", "arguments": ["example.jpg", "What is the main topic of the document?"]}], "task_links": [{"source": "Image Segmentation", "target": "Object Detection"}, {"source": "Object Detection", "target": "Document Question Answering"}], "type": "chain"}
{"id": "27799210", "seed": 280195, "n_tools": 3, "sampled_nodes": [{"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": []}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image-to-Image", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Sentence Similarity"}], "user_request": "I have an image 'example.jpg', please transform it into a target image style, then answer the question: 'What are the main colors in the transformed image?', and tell me how similar this question is to the given answer.", "task_steps": ["Step 1: Convert the original image 'example.jpg' into a target image style using Image-to-Image model.", "Step 2: Answer a specific user question based on the transformed image using Visual Question Answering.", "Step 3: Determine the similarity between the user question and the answer provided by Visual Question Answering using Sentence Similarity."], "task_nodes": [{"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Sentence Similarity", "arguments": ["What are the main colors in the transformed image?", "<node-2>"]}, {"task": "Visual Question Answering", "arguments": ["<node-0>", "What are the main colors in the transformed image?"]}], "task_links": [{"source": "Image-to-Image", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Sentence Similarity"}], "type": "chain"}
{"id": "25898615", "seed": 317505, "n_tools": 5, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Visual Question Answering", "target": "Image Editing"}, {"source": "Image Editing", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Document Question Answering"}], "user_request": "I have an image (example.jpg) related to a product. I want to know what color the product is, change the product's color to blue, apply enhancements, classify the image into a table, and answer a specific question regarding the classified information.", "task_steps": ["Step 1: Answer a question related to the provided image (example.jpg) using Visual Question Answering.", "Step 2: Edit the image based on the answer obtained from Step 1 using Image Editing.", "Step 3: Apply an image-to-image transformation to modify the edited image from Step 2 using Image-to-Image.", "Step 4: Perform tabular classification on the transformed image from Step 3 using Tabular Classification.", "Step 5: Answer a question related to the classified table from Step 4 using Document Question Answering."], "task_nodes": [{"task": "Visual Question Answering", "arguments": ["example.jpg", "What is the color of the product in the image?"]}, {"task": "Image Editing", "arguments": ["example.jpg", "Change the color of the product in the image to blue."]}, {"task": "Image-to-Image", "arguments": ["<node-1>"]}, {"task": "Tabular Classification", "arguments": ["<node-2>"]}, {"task": "Document Question Answering", "arguments": ["<node-3>", "What is the price of the product?"]}], "task_links": [{"source": "Visual Question Answering", "target": "Image Editing"}, {"source": "Image Editing", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Document Question Answering"}], "type": "chain"}
{"id": "39895729", "seed": 231518, "n_tools": 1, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}], "sampled_links": [], "user_request": "Please help me transcribe the content of the audio file 'example.wav' into text.", "task_steps": ["Transcribe the audio example.wav into text."], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["example.wav"]}], "task_links": [], "type": "single"}
{"id": "40854641", "seed": 876657, "n_tools": 4, "sampled_nodes": [{"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Text-to-Image", "target": "Visual Question Answering"}, {"source": "Translation", "target": "Text-to-Speech"}, {"source": "Visual Question Answering", "target": "Translation"}], "user_request": "Generate a tropical beach image based on the text description 'Beautiful sunset on a sandy beach with palm trees', then answer the question 'What is the prominent feature of the image?' in English, and translate the answer to Spanish, finally, convert the translated answer into speech.", "task_steps": ["Step 1: Generate an image based on the user's text description.", "Step 2: Answer a question about the generated image.", "Step 3: Translate the answer into another language.", "Step 4: Convert the translated answer into speech."], "task_nodes": [{"task": "Text-to-Image", "arguments": ["Beautiful sunset on a sandy beach with palm trees"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}, {"task": "Translation", "arguments": ["<node-3>"]}, {"task": "Visual Question Answering", "arguments": ["<node-0>", "What is the prominent feature of the image?"]}], "task_links": [{"source": "Text-to-Image", "target": "Visual Question Answering"}, {"source": "Translation", "target": "Text-to-Speech"}, {"source": "Visual Question Answering", "target": "Translation"}], "type": "chain"}
{"id": "23693786", "seed": 227886, "n_tools": 4, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Conversational", "target": "Text-to-Video"}, {"source": "Object Detection", "target": "Translation"}, {"source": "Translation", "target": "Conversational"}], "user_request": "I have an image 'example.jpg' containing various objects in a room. I would like to detect the objects in the image and have their labels translated to French. Based on the translated labels, I want to generate a conversational response and finally create a video that visualizes the generated response.", "task_steps": ["Detect objects in an image and label them", "Translate the detection labels to another language", "Generate a conversational response based on the translated labels", "Create a video based on the generated response"], "task_nodes": [{"task": "Conversational", "arguments": ["<node-3>"]}, {"task": "Object Detection", "arguments": ["example.jpg"]}, {"task": "Text-to-Video", "arguments": ["<node-0>"]}, {"task": "Translation", "arguments": ["<node-1>"]}], "task_links": [{"source": "Conversational", "target": "Text-to-Video"}, {"source": "Object Detection", "target": "Translation"}, {"source": "Translation", "target": "Conversational"}], "type": "chain"}
{"id": "16157027", "seed": 355391, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Token Classification"}, {"source": "Summarization", "target": "Image Editing"}, {"source": "Token Classification", "target": "Summarization"}], "user_request": "User uploads 'example.wav' and says, 'Create a thumbnail image for my blog post about visiting the Eiffel Tower on June 5th. Make the background sky blue and add some clouds. Here's an image 'example.jpg' for you to work with.'", "task_steps": ["Step 1: Extract the main command and emotion from the user's audio input.", "Step 2: Identify and label specific entities in the summarized text.", "Step 3: Generate a shorter version of the input text by summarizing", "Step 4: Modify the input image based on the summarized and entity-labeled text."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Image Editing", "arguments": ["<node-2>", "example.jpg"]}, {"task": "Summarization", "arguments": ["<node-3>"]}, {"task": "Token Classification", "arguments": ["<node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Token Classification"}, {"source": "Summarization", "target": "Image Editing"}, {"source": "Token Classification", "target": "Summarization"}], "type": "chain"}
{"id": "16690264", "seed": 379628, "n_tools": 5, "sampled_nodes": [{"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Object Detection", "target": "Summarization"}, {"source": "Summarization", "target": "Text Generation"}, {"source": "Text Generation", "target": "Translation"}, {"source": "Translation", "target": "Sentence Similarity"}], "user_request": "I have an image 'example.jpg' containing a variety of objects. I'd like to identify the objects, provide a brief summary of them, generate a descriptive text, translate this text into French, and finally compare the similarity between the translated text and my input text 'C'est une sc\u00e8ne int\u00e9ressante'. Can you help me with this?", "task_steps": ["Step 1: Detect objects in the image", "Step 2: Summarize the detected objects' labels", "Step 3: Generate a text based on the summarization", "Step 4: Translate the generated text into a different language", "Step 5: Check the similarity of the translated text with a user-provided text"], "task_nodes": [{"task": "Object Detection", "arguments": ["example.jpg"]}, {"task": "Sentence Similarity", "arguments": ["<node-4>", "C'est une sc\u00e8ne int\u00e9ressante"]}, {"task": "Summarization", "arguments": ["<node-0>"]}, {"task": "Text Generation", "arguments": ["<node-2>"]}, {"task": "Translation", "arguments": ["<node-3>"]}], "task_links": [{"source": "Object Detection", "target": "Summarization"}, {"source": "Summarization", "target": "Text Generation"}, {"source": "Text Generation", "target": "Translation"}, {"source": "Translation", "target": "Sentence Similarity"}], "type": "chain"}
{"id": "31321657", "seed": 895047, "n_tools": 3, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Token Classification"}, {"source": "Token Classification", "target": "Sentence Similarity"}], "user_request": "I have an audio file 'example.wav' from a news segment and I want to know how similar its content is to the topic of my research paper: 'The impact of climate change on polar bears'. Please analyze the audio and measure its similarity to my research paper topic.", "task_steps": ["Step 1: Convert the audio file into text by classifying the audio.", "Step 2: Perform token classification on the converted text to identify named entities.", "Step 3: Measure the similarity between the obtained entity names and the provided text."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Sentence Similarity", "arguments": ["<node-2>", "The impact of climate change on polar bears"]}, {"task": "Token Classification", "arguments": ["<node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Token Classification"}, {"source": "Token Classification", "target": "Sentence Similarity"}], "type": "chain"}
{"id": "27568348", "seed": 386563, "n_tools": 2, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}], "sampled_links": [{"source": "Audio-to-Audio", "target": "Audio Classification"}], "user_request": "I have an audio recording (example.wav) of a person speaking, and I'd like to first enhance its quality and then classify the emotion behind the speech.", "task_steps": ["Step 1: Enhance the audio quality using Audio-to-Audio tool.", "Step 2: Classify the enhanced audio to identify the emotion using Audio Classification tool."], "task_nodes": [{"task": "Audio Classification", "arguments": ["<node-1>"]}, {"task": "Audio-to-Audio", "arguments": ["example.wav"]}], "task_links": [{"source": "Audio-to-Audio", "target": "Audio Classification"}], "type": "chain"}
{"id": "58966953", "seed": 167575, "n_tools": 1, "sampled_nodes": [{"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I would like to find the answer to the following question: 'What are the benefits of exercising regularly?' from this text: 'Regular exercise has a plethora of benefits. It helps increase your energy levels, improves sleep, maintains a healthy body weight, and reduces the risk of chronic diseases.'", "task_steps": ["Step 1: Retrieve the answer to a question from a given text using the Question Answering model."], "task_nodes": [{"task": "Question Answering", "arguments": ["What are the benefits of exercising regularly?", "Regular exercise has a plethora of benefits. It helps increase your energy levels, improves sleep, maintains a healthy body weight, and reduces the risk of chronic diseases."]}], "task_links": [], "type": "single"}
{"id": "10968882", "seed": 643256, "n_tools": 3, "sampled_nodes": [{"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}], "sampled_links": [{"source": "Tabular Classification", "target": "Question Answering"}, {"source": "Question Answering", "target": "Text-to-Video"}], "user_request": "I have an image (example.jpg) which contains information about my investments in a tabular format and I would like to generate a video about the highest-growth investment. My question is: Which investment has had the highest growth?", "task_steps": ["1. Perform depth estimation on the given image", "2. Perform tabular classification on the depth-estimated image", "3. Retrieve an answer to a user question from the classified table", "4. Generate a video from the retrieved text answer"], "task_nodes": [{"task": "Tabular Classification", "arguments": ["example.jpg"]}, {"task": "Question Answering", "arguments": ["<node-0>", "Which investment has had the highest growth?"]}, {"task": "Text-to-Video", "arguments": ["<node-1>"]}], "task_links": [{"source": "Tabular Classification", "target": "Question Answering"}, {"source": "Question Answering", "target": "Text-to-Video"}], "type": "chain"}
{"id": "21292042", "seed": 151003, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Question Answering"}, {"source": "Audio Classification", "target": "Token Classification"}, {"source": "Image-to-Text", "target": "Question Answering"}], "user_request": "I have an image example.jpg with some text and an audio file example.wav, where someone is speaking. Can you help me find the answer to the question 'When is the event happening?' using the text from the image, and tell me what entities are mentioned in the audio?", "task_steps": ["Step 1: Extract text from an image.", "Step 2: Classify audio data into meaningful text.", "Step 3: Answer a question using the extracted text.", "Step 4: Perform token classification on the classified audio text."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Image-to-Text", "arguments": ["example.jpg"]}, {"task": "Question Answering", "arguments": ["<output from node-1>", "When is the event happening?"]}, {"task": "Token Classification", "arguments": ["<output from node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Question Answering"}, {"source": "Audio Classification", "target": "Token Classification"}, {"source": "Image-to-Text", "target": "Question Answering"}], "type": "dag"}
{"id": "96041123", "seed": 176854, "n_tools": 1, "sampled_nodes": [{"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have a long article that I need to provide a summary for. Can you please generate a shorter version of the article while preserving the important information? Here is the text: 'The quick brown fox jumps over the lazy dog. The quick brown fox is very fast and agile, and the lazy dog is slow and sleepy. The fox then finds some food and shares it with the dog. Eventually, the dog becomes active and energetic, and they both play together. Finally, they become friends and live happily ever after.'", "task_steps": ["Create a summary of a given text"], "task_nodes": [{"task": "Summarization", "arguments": ["The quick brown fox jumps over the lazy dog. The quick brown fox is very fast and agile, and the lazy dog is slow and sleepy. The fox then finds some food and shares it with the dog. Eventually, the dog becomes active and energetic, and they both play together. Finally, they become friends and live happily ever after."]}], "task_links": [], "type": "single"}
{"id": "83662522", "seed": 892546, "n_tools": 1, "sampled_nodes": [{"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have a long document regarding the history of computer science and would like to get a summarized version of it. The text document is as follows: 'Computer science is the study of algorithmic processes and computational machines. As a discipline, computer science spans a range of topics from theoretical studies of algorithms, computation, and information to the practical issues of implementing computing systems in hardware and software. The history of computer science began long before our modern discipline of computer science, starting with the abacus in 2500 BC. With the invention of the analytical engine in the 19th century by Charles Babbage, and later the development of the electronic computer, computer science has come a long way. Some important milestones include the invention of the transistor in 1947, the development of the integrated circuit in 1958, and the creation of high-level programming languages, such as Python, in the late 20th century.'", "task_steps": ["Step 1: Summarize the given text to preserve important information"], "task_nodes": [{"task": "Summarization", "arguments": ["Computer science is the study of algorithmic processes and computational machines. As a discipline, computer science spans a range of topics from theoretical studies of algorithms, computation, and information to the practical issues of implementing computing systems in hardware and software. The history of computer science began long before our modern discipline of computer science, starting with the abacus in 2500 BC. With the invention of the analytical engine in the 19th century by Charles Babbage, and later the development of the electronic computer, computer science has come a long way. Some important milestones include the invention of the transistor in 1947, the development of the integrated circuit in 1958, and the creation of high-level programming languages, such as Python, in the late 20th century."]}], "task_links": [], "type": "single"}
{"id": "21770383", "seed": 290971, "n_tools": 3, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Question Answering"}, {"source": "Question Answering", "target": "Text-to-Speech"}], "user_request": "User provides an audio file 'example.wav' containing a question and a text document 'source_text.txt' that contains information to answer the question.", "task_steps": ["Step 1: Convert the user's audio question to text using Automatic Speech Recognition.", "Step 2: Find the answer to the converted text question using Question Answering model from a given document.", "Step 3: Convert the answer from text format to audio format using Text-to-Speech."], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["example.wav"]}, {"task": "Question Answering", "arguments": ["source_text.txt", "<node-0>"]}, {"task": "Text-to-Speech", "arguments": ["<node-1>"]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Question Answering"}, {"source": "Question Answering", "target": "Text-to-Speech"}], "type": "chain"}
{"id": "14234807", "seed": 483940, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Conversational"}, {"source": "Conversational", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Text-to-Image"}], "user_request": "I have an audio file 'example.wav' where a person asks some information about an image 'example.jpg'. Please help me know what the person is asking about and provide a conversational response while generating a relevant image.", "task_steps": ["Step 1: Classify the audio to obtain a text label.", "Step 2: Use the text label and the image to answer the visual question.", "Step 3: Generate a conversational response based on the visual question answer.", "Step 4: Create an image based on the conversational response."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Conversational", "arguments": ["<node-0>"]}, {"task": "Text-to-Image", "arguments": ["<node-3>"]}, {"task": "Visual Question Answering", "arguments": ["example.jpg", "<node-1>"]}], "task_links": [{"source": "Audio Classification", "target": "Conversational"}, {"source": "Conversational", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Text-to-Image"}], "type": "chain"}
{"id": "19267601", "seed": 934205, "n_tools": 1, "sampled_nodes": [{"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "Find the answer to the question 'When was the Eiffel Tower completed?' from the text 'The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It was named after the engineer Gustave Eiffel, whose company designed and built the tower. The construction began in 1887 and was completed in 1889.'", "task_steps": ["Step 1: Provide a text document and a question related to the content within the document."], "task_nodes": [{"task": "Question Answering", "arguments": ["The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It was named after the engineer Gustave Eiffel, whose company designed and built the tower. The construction began in 1887 and was completed in 1889.", "When was the Eiffel Tower completed?"]}], "task_links": [], "type": "single"}
{"id": "16222823", "seed": 884256, "n_tools": 4, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Editing", "target": "Depth Estimation"}, {"source": "Depth Estimation", "target": "Image Classification"}, {"source": "Depth Estimation", "target": "Image-to-Text"}], "user_request": "I have an image named 'example.jpg'. I would like to change the color of the car in the image to red based on the text description 'The main car should be red in color'. Then, I want to analyze the depth of the objects in the edited image, extract a textual description from the image, and classify the image.", "task_steps": ["Step 1: Edit the image based on the provided text description.", "Step 2: Estimate the depth of the edited image.", "Step 3: Convert the edited image with depth information to text.", "Step 4: Classify the edited image with depth information."], "task_nodes": [{"task": "Depth Estimation", "arguments": ["<node-2>"]}, {"task": "Image Classification", "arguments": ["<node-0>"]}, {"task": "Image Editing", "arguments": ["example.jpg", "The main car should be red in color"]}, {"task": "Image-to-Text", "arguments": ["<node-0>"]}], "task_links": [{"source": "Image Editing", "target": "Depth Estimation"}, {"source": "Depth Estimation", "target": "Image Classification"}, {"source": "Depth Estimation", "target": "Image-to-Text"}], "type": "dag"}
{"id": "23627042", "seed": 625308, "n_tools": 1, "sampled_nodes": [{"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [], "user_request": "Please classify the image 'example.jpg' and provide the class label for the image.", "task_steps": ["Step 1: Classify the given image using the Image Classification tool."], "task_nodes": [{"task": "Image Classification", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "10137185", "seed": 496032, "n_tools": 3, "sampled_nodes": [{"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Editing", "target": "Image-to-Text"}, {"source": "Token Classification", "target": "Image Editing"}], "user_request": "I have an image 'example.jpg' and a textual description 'Make the car in the image red and the sky blue'. I want the image to be edited based on the description and then convert the edited image to text.", "task_steps": ["1. Perform Token Classification on the provided text description to identify necessary entities.", "2. Use Image Editing tool to modify 'example.jpg' image based on the entities detected in step 1.", "3. Convert the edited image from step 2 to text using the Image-to-Text tool."], "task_nodes": [{"task": "Image Editing", "arguments": ["<node-2>", "example.jpg"]}, {"task": "Image-to-Text", "arguments": ["<node-0>"]}, {"task": "Token Classification", "arguments": ["Make the car in the image red and the sky blue"]}], "task_links": [{"source": "Image Editing", "target": "Image-to-Text"}, {"source": "Token Classification", "target": "Image Editing"}], "type": "chain"}
{"id": "21025473", "seed": 533623, "n_tools": 3, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": []}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Conversational", "target": "Token Classification"}, {"source": "Token Classification", "target": "Sentence Similarity"}], "user_request": "I need help understanding the impact of global warming on polar bears. Please provide a conversational response and measure the similarity between my original question and the response after performing token classification.", "task_steps": ["Step 1: Generate a conversational response given a user prompt", "Step 2: Perform token classification on the conversational response", "Step 3: Calculate the sentence similarity between the original user prompt and the token classification output"], "task_nodes": [{"task": "Conversational", "arguments": ["I need help understanding the impact of global warming on polar bears"]}, {"task": "Sentence Similarity", "arguments": ["I need help understanding the impact of global warming on polar bears", "<node-2>"]}, {"task": "Token Classification", "arguments": ["<node-0>"]}], "task_links": [{"source": "Conversational", "target": "Token Classification"}, {"source": "Token Classification", "target": "Sentence Similarity"}], "type": "chain"}
{"id": "15329769", "seed": 569604, "n_tools": 6, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Segmentation", "target": "Object Detection"}, {"source": "Object Detection", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Image Editing"}, {"source": "Image Editing", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Document Question Answering"}], "user_request": "I have an image (example.jpg) containing an object and a table. I need to identify the color of the largest object in the image, change its color to blue, and then classify the content of the table, finally answering a question about the most common value in column B.", "task_steps": ["1. Perform image segmentation on example.jpg.", "2. Detect objects in the segmented image.", "3. Answer the question: 'What color is the largest object in the image?'", "4. Edit the image to change the color of the largest object to blue.", "5. Classify the content of the table in the edited image.", "6. Answer the question: 'What is the most common value in column B of the table?'"], "task_nodes": [{"task": "Image Segmentation", "arguments": ["example.jpg"]}, {"task": "Object Detection", "arguments": ["<node-0>"]}, {"task": "Visual Question Answering", "arguments": ["<node-1>", "What color is the largest object in the image?"]}, {"task": "Image Editing", "arguments": ["Change the color of the largest object to blue", "<node-2>"]}, {"task": "Tabular Classification", "arguments": ["<node-3>"]}, {"task": "Document Question Answering", "arguments": ["<node-4>", "What is the most common value in column B of the table?"]}], "task_links": [{"source": "Image Segmentation", "target": "Object Detection"}, {"source": "Object Detection", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Image Editing"}, {"source": "Image Editing", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Document Question Answering"}], "type": "chain"}
{"id": "18330948", "seed": 581084, "n_tools": 7, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Document Question Answering"}, {"source": "Document Question Answering", "target": "Text Generation"}, {"source": "Image-to-Image", "target": "Visual Question Answering"}, {"source": "Text-to-Image", "target": "Image-to-Image"}, {"source": "Visual Question Answering", "target": "Text-to-Image"}], "user_request": "I have an audio file named example.wav and an image named example.jpg. I need to enhance the audio quality of the example.wav file, then transcribe it to text. I need you to answer a question about the example.jpg image using the transcribed text as context. Generate an image based on the answer you provide. Enhance the generated image. I have a question about the enhanced image, answer it using the transcribed text for context. Lastly, generate new related text based on the answer to the question about the enhanced image.", "task_steps": ["Step 1: Enhance audio quality in the example.wav file.", "Step 2: Transcribe the audio from example.wav to text.", "Step 3: Answer a question about an example.jpg image based on the transcribed text.", "Step 4: Generate an image based on a response from the Visual Question Answering tool.", "Step 5: Enhance the generated image.", "Step 6: Answer a question about the enhanced image based on the transcribed text.", "Step 7: Generate new text based on the response from Document Question Answering."], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["example.wav"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-0>"]}, {"task": "Document Question Answering", "arguments": ["example.jpg", "<node-1>"]}, {"task": "Image-to-Image", "arguments": ["<node-5>"]}, {"task": "Text Generation", "arguments": ["<node-2>"]}, {"task": "Text-to-Image", "arguments": ["<node-6>"]}, {"task": "Visual Question Answering", "arguments": ["<node-3>", "<node-1>"]}], "task_links": [{"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}, {"source": "Automatic Speech Recognition", "target": "Document Question Answering"}, {"source": "Document Question Answering", "target": "Text Generation"}, {"source": "Image-to-Image", "target": "Visual Question Answering"}, {"source": "Text-to-Image", "target": "Image-to-Image"}, {"source": "Visual Question Answering", "target": "Text-to-Image"}], "type": "chain"}
{"id": "28153655", "seed": 906032, "n_tools": 4, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Document Question Answering", "target": "Question Answering"}, {"source": "Question Answering", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}], "user_request": "Please help me answer the question 'What is the main purpose of the document?' based on the provided example.jpg file. Then, I want to retrieve more information about the document's purpose by using this text 'The document is about an innovative AI solution for climate change forecasting. It discusses the techniques and algorithms used by the AI model and its potential impact on the world.' Please convert the retrieved answer into an enhanced audio.", "task_steps": ["Step 1: Answer the given question based on the example.jpg document image.", "Step 2: Retrieve information from a user-specified text using question-answering.", "Step 3: Convert the retrieved answer into speech using Text-to-Speech.", "Step 4: Enhance the audio using Audio-to-Audio."], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["<node-3>"]}, {"task": "Document Question Answering", "arguments": ["example.jpg", "What is the main purpose of the document?"]}, {"task": "Question Answering", "arguments": ["The document is about an innovative AI solution for climate change forecasting. It discusses the techniques and algorithms used by the AI model and its potential impact on the world.", "<node-1>"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}], "task_links": [{"source": "Document Question Answering", "target": "Question Answering"}, {"source": "Question Answering", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}], "type": "chain"}
{"id": "25964611", "seed": 293076, "n_tools": 3, "sampled_nodes": [{"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Question Answering", "target": "Translation"}, {"source": "Translation", "target": "Text-to-Image"}], "user_request": "I have a document in English 'example.txt' which contains information about a vacation spot. I want to find the answer to the question 'What is the best time to visit this place?' and have it translated into French. Generate an image based on the translated text.", "task_steps": ["Step 1: Find the answer to a question within a given text using the 'Question Answering' tool", "Step 2: Translate the answer obtained from Step 1 into another language using the 'Translation' tool", "Step 3: Generate an image based on the translated text using the 'Text-to-Image' tool"], "task_nodes": [{"task": "Question Answering", "arguments": ["example.txt", "What is the best time to visit this place?"]}, {"task": "Text-to-Image", "arguments": ["<node-2>"]}, {"task": "Translation", "arguments": ["<node-0>"]}], "task_links": [{"source": "Question Answering", "target": "Translation"}, {"source": "Translation", "target": "Text-to-Image"}], "type": "chain"}
{"id": "26196526", "seed": 668010, "n_tools": 4, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Text-to-Speech", "target": "Audio-to-Audio"}, {"source": "Token Classification", "target": "Image Editing"}, {"source": "Token Classification", "target": "Text-to-Speech"}], "user_request": "Please modify the example.jpg image to represent the sentence: 'Make the background blue and add a red car in the foreground.' Then, convert the rest of the text in this request into enhanced speech and download the audio file.", "task_steps": ["Step 1: Identify entities and part-of-speech tagging in the text", "Step 2: Modify the input image based on the text information", "Step 3: Convert the remaining text into speech", "Step 4: Enhance the generated speech audio"], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["<node-2>"]}, {"task": "Image Editing", "arguments": ["example.jpg", "<node-3.output.instructions>"]}, {"task": "Text-to-Speech", "arguments": ["<node-3.output.text>"]}, {"task": "Token Classification", "arguments": ["Make the background blue and add a red car in the foreground. Then, convert the rest of the text in this request into enhanced speech and download the audio file."]}], "task_links": [{"source": "Text-to-Speech", "target": "Audio-to-Audio"}, {"source": "Token Classification", "target": "Image Editing"}, {"source": "Token Classification", "target": "Text-to-Speech"}], "type": "dag"}
{"id": "40823143", "seed": 486889, "n_tools": 1, "sampled_nodes": [{"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [], "user_request": "I need assistance in converting the following text to an audio file: 'Welcome to our annual conference! We are glad to have you here with us today.'", "task_steps": ["Convert provided text to natural-sounding speech audio"], "task_nodes": [{"task": "Text-to-Speech", "arguments": ["Welcome to our annual conference! We are glad to have you here with us today."]}], "task_links": [], "type": "single"}
{"id": "17904189", "seed": 59120, "n_tools": 5, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Object Detection", "target": "Summarization"}, {"source": "Summarization", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}, {"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}], "user_request": "I have a color-coded floorplan image (example.jpg), please identify objects in the image, provide me with an audio description of detected objects, then transcribe that audio back to text and finally give me a summarized version of the detected objects description.", "task_steps": ["Step 1: Use Object Detection to identify objects in the image.", "Step 2: Convert detected objects' labels into speech using Text-to-Speech.", "Step 3: Process the speech output using Audio-to-Audio.", "Step 4: Transcribe the processed speech back to text using Automatic Speech Recognition.", "Step 5: Summarize the transcribed text using Summarization."], "task_nodes": [{"task": "Object Detection", "arguments": ["example.jpg"]}, {"task": "Summarization", "arguments": ["<node-0>"]}, {"task": "Text-to-Speech", "arguments": ["<node-1>"]}, {"task": "Audio-to-Audio", "arguments": ["<node-2>"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-3>"]}], "task_links": [{"source": "Object Detection", "target": "Summarization"}, {"source": "Summarization", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}, {"source": "Audio-to-Audio", "target": "Automatic Speech Recognition"}], "type": "chain"}
{"id": "25410646", "seed": 858343, "n_tools": 5, "sampled_nodes": [{"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Editing", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Visual Question Answering"}, {"source": "Summarization", "target": "Text-to-Speech"}, {"source": "Visual Question Answering", "target": "Summarization"}], "user_request": "Please modify example.jpg by making the main object red and background green. Then, make the edited image look like an oil painting. After that, answer these questions about the image: 'What is the main object? How many similar objects are there?' Summarize the answers and convert the summarized text into speech.", "task_steps": ["Step 1: Modify the example.jpg image based on a given user description.", "Step 2: Transform the modified image to match a source image's characteristics.", "Step 3: Answer a user's questions based on the transformed image.", "Step 4: Summarize the answers to the user's questions.", "Step 5: Convert the summarized text into speech."], "task_nodes": [{"task": "Image Editing", "arguments": ["make the main object red and background green", "example.jpg"]}, {"task": "Image-to-Image", "arguments": ["<node-0>"]}, {"task": "Summarization", "arguments": ["<node-4>"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}, {"task": "Visual Question Answering", "arguments": ["<node-1>", "What is the main object? How many similar objects are there?"]}], "task_links": [{"source": "Image Editing", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Visual Question Answering"}, {"source": "Summarization", "target": "Text-to-Speech"}, {"source": "Visual Question Answering", "target": "Summarization"}], "type": "chain"}
{"id": "22183403", "seed": 636998, "n_tools": 4, "sampled_nodes": [{"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Text-to-Image", "target": "Visual Question Answering"}, {"source": "Translation", "target": "Text-to-Image"}, {"source": "Visual Question Answering", "target": "Text-to-Video"}], "user_request": "I have a text in English that I need to be translated to Spanish: 'The beautiful sunset at the beach'. Then, I would like to have an image related to this translated text. Also, please answer the following question about the image: 'What is the main color in the image?'. Based on the answer to this question, create a video that represents the answer.", "task_steps": ["Step 1: Translate the text from English to Spanish", "Step 2: Create an image based on the translated text", "Step 3: Answer a question about the generated image", "Step 4: Generate a video based on the answer from step 3"], "task_nodes": [{"task": "Text-to-Image", "arguments": ["<node-2>"]}, {"task": "Text-to-Video", "arguments": ["<node-3>"]}, {"task": "Translation", "arguments": ["The beautiful sunset at the beach"]}, {"task": "Visual Question Answering", "arguments": ["<node-0>", "What is the main color in the image?"]}], "task_links": [{"source": "Text-to-Image", "target": "Visual Question Answering"}, {"source": "Translation", "target": "Text-to-Image"}, {"source": "Visual Question Answering", "target": "Text-to-Video"}], "type": "chain"}
{"id": "17381010", "seed": 910066, "n_tools": 6, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": []}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image-to-Image", "target": "Depth Estimation"}, {"source": "Depth Estimation", "target": "Image Classification"}, {"source": "Image Classification", "target": "Text Generation"}, {"source": "Text Generation", "target": "Summarization"}, {"source": "Summarization", "target": "Sentence Similarity"}], "user_request": "Transform the example.jpg image to a night scene, estimate the depth of objects in the scene, classify it as indoor or outdoor, generate a brief description of the scene, and compare the similarity between this description and the reference text 'A serene nighttime outdoor landscape showed a serene and peaceful environment'.", "task_steps": ["1. Transform the source image 'example.jpg' to match the characteristics of a night scene using Image-to-Image model.", "2. Estimate the depth of objects in the transformed image using a Depth Estimation model.", "3. Classify the scene as indoor or outdoor using Image Classification model.", "4. Generate a text description of the scene based on the classification result using Text Generation model.", "5. Summarize the generated text description using a Summarization model.", "6. Determine the similarity between the summarized text and user-provided reference text using Sentence Similarity model."], "task_nodes": [{"task": "Depth Estimation", "arguments": ["<node-2>"]}, {"task": "Image Classification", "arguments": ["<node-0>"]}, {"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Sentence Similarity", "arguments": ["<node-4>", "A serene nighttime outdoor landscape showed a serene and peaceful environment"]}, {"task": "Summarization", "arguments": ["<node-5>"]}, {"task": "Text Generation", "arguments": ["<node-1>"]}], "task_links": [{"source": "Image-to-Image", "target": "Depth Estimation"}, {"source": "Depth Estimation", "target": "Image Classification"}, {"source": "Image Classification", "target": "Text Generation"}, {"source": "Text Generation", "target": "Summarization"}, {"source": "Summarization", "target": "Sentence Similarity"}], "type": "chain"}
{"id": "17578906", "seed": 579005, "n_tools": 5, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Translation"}, {"source": "Translation", "target": "Image Editing"}, {"source": "Image Editing", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Image-to-Text"}], "user_request": "I have an audio file 'example.wav' describing some modifications to be done to an image 'example.jpg'. I need the audio transcribed to text, translated to French, and then want the changes to be made to the image accordingly. Then, I need an image-to-image transformation of the edited image, and finally, an image description of the transformed image.", "task_steps": ["Step 1: Convert the audio file into text using Automatic Speech Recognition", "Step 2: Translate the transcribed text into another language", "Step 3: Edit an image according to the translated text", "Step 4: Modify the edited image using image-to-image transformation", "Step 5: Get the final image description using Image-to-Text"], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["example.wav"]}, {"task": "Translation", "arguments": ["<node-0>"]}, {"task": "Image Editing", "arguments": ["<node-4>", "example.jpg"]}, {"task": "Image-to-Image", "arguments": ["<node-1>"]}, {"task": "Image-to-Text", "arguments": ["<node-2>"]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Translation"}, {"source": "Translation", "target": "Image Editing"}, {"source": "Image Editing", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Image-to-Text"}], "type": "chain"}
{"id": "11505135", "seed": 575899, "n_tools": 5, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Text Generation"}, {"source": "Text Generation", "target": "Token Classification"}, {"source": "Token Classification", "target": "Conversational"}, {"source": "Conversational", "target": "Summarization"}], "user_request": "I'd like to control my smart home devices by voice. Please configure a system for me to understand my voice commands, generate a relevant text response, classify important tokens, generate a meaningful conversational response, and summarize the response for easy understanding. Here's an audio sample of my voice command: example.wav", "task_steps": ["Step 1: Convert user's voice command into text", "Step 2: Generate a relevant text based on the converted command", "Step 3: Classify tokens in the generated text for better understanding", "Step 4: Generate a conversational response based on token classification", "Step 5: Summarize the conversational response to provide a concise answer"], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Text Generation", "arguments": ["<node-0>"]}, {"task": "Token Classification", "arguments": ["<node-3>"]}, {"task": "Conversational", "arguments": ["<node-4>"]}, {"task": "Summarization", "arguments": ["<node-1>"]}], "task_links": [{"source": "Audio Classification", "target": "Text Generation"}, {"source": "Text Generation", "target": "Token Classification"}, {"source": "Token Classification", "target": "Conversational"}, {"source": "Conversational", "target": "Summarization"}], "type": "chain"}
{"id": "15624976", "seed": 234058, "n_tools": 3, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": []}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Sentence Similarity"}, {"source": "Text-to-Speech", "target": "Automatic Speech Recognition"}], "user_request": "I have a text file containing some speech that I want to test the performance of an Automatic Speech Recognition system. The text is 'This is an example test for speech recognition.' Please analyze the accuracy of the transcription.", "task_steps": ["Step 1: Convert the user's text input into audio using Text-to-Speech.", "Step 2: Transcribe the audio back to text using Automatic Speech Recognition.", "Step 3: Compare the original text input with the transcribed text using Sentence Similarity to evaluate the performance of the ASR."], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["<node-2>"]}, {"task": "Sentence Similarity", "arguments": ["This is an example test for speech recognition.", "<node-0>"]}, {"task": "Text-to-Speech", "arguments": ["This is an example test for speech recognition."]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Sentence Similarity"}, {"source": "Text-to-Speech", "target": "Automatic Speech Recognition"}], "type": "chain"}
{"id": "18468003", "seed": 910624, "n_tools": 1, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}], "sampled_links": [], "user_request": "I have a noisy audio file 'example.wav' and I need to enhance its speech quality.", "task_steps": ["Step 1: Enhance the speech quality of the given audio file 'example.wav'"], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["example.wav"]}], "task_links": [], "type": "single"}
{"id": "71493397", "seed": 813908, "n_tools": 1, "sampled_nodes": [{"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I need to segment the objects in the provided image 'example.jpg'. Please perform image segmentation on this image.", "task_steps": ["Step 1: Perform image segmentation on the given image"], "task_nodes": [{"task": "Image Segmentation", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "32470251", "seed": 66964, "n_tools": 1, "sampled_nodes": [{"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [], "user_request": "Please use Object Detection model to identify objects in the provided image 'example.jpg' and label them with bounding boxes.", "task_steps": ["Step 1: Use Object Detection model to detect objects in the image"], "task_nodes": [{"task": "Object Detection", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "23170074", "seed": 869366, "n_tools": 1, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "Could you please help me answer the following question related to the content present in the image example.jpg? The question is: 'What is the main topic of the document?'", "task_steps": ["Answer a question about the content of an example document image"], "task_nodes": [{"task": "Document Question Answering", "arguments": ["example.jpg", "What is the main topic of the document?"]}], "task_links": [], "type": "single"}
{"id": "26752140", "seed": 164165, "n_tools": 2, "sampled_nodes": [{"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Question Answering", "target": "Text-to-Speech"}], "user_request": "I have a question: 'What is the capital of France?' Please search for the answer in the following text: 'France, in Western Europe, is known for its rich history, culture, and landmarks. The capital of France is Paris, which is also the largest city in the country.' Then, provide the answer in both audio and text formats.", "task_steps": ["Step 1: Retrieve the answer to a user's question using the Question Answering model.", "Step 2: Convert the retrieved answer to speech using the Text-to-Speech model.", "Step 3: Transcribe the generated speech back to text using the Automatic Speech Recognition model."], "task_nodes": [{"task": "Question Answering", "arguments": ["What is the capital of France?", "France, in Western Europe, is known for its rich history, culture, and landmarks. The capital of France is Paris, which is also the largest city in the country."]}, {"task": "Text-to-Speech", "arguments": ["<node-1>"]}], "task_links": [{"source": "Question Answering", "target": "Text-to-Speech"}], "type": "chain"}
{"id": "28842621", "seed": 781369, "n_tools": 3, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Editing", "target": "Image-to-Text"}, {"source": "Image-to-Text", "target": "Conversational"}], "user_request": "I have an image file named 'example.jpg' that contains a picture of a red car on a green background. I would like to edit the image to have a blue car on a white background and then get a conversation about the image after the changes were made.", "task_steps": ["Step 1: Edit an image to match the given text description.", "Step 2: Extract text from the edited image.", "Step 3: Generate a conversational response based on the extracted text."], "task_nodes": [{"task": "Conversational", "arguments": ["<node-2>"]}, {"task": "Image Editing", "arguments": ["Change the red car to blue and the green background to white.", "example.jpg"]}, {"task": "Image-to-Text", "arguments": ["<node-1>"]}], "task_links": [{"source": "Image Editing", "target": "Image-to-Text"}, {"source": "Image-to-Text", "target": "Conversational"}], "type": "chain"}
{"id": "31348629", "seed": 703182, "n_tools": 2, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Question Answering", "input-type": ["text", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Question Answering"}], "user_request": "I have an audio file named 'example.wav' that contains a question about voice assistants. Can you transcribe the audio and help me find an answer?", "task_steps": ["Step 1: Convert the user's audio question to text", "Step 2: Generate a conversational response based on the transcribed text", "Step 3: Retrieve the answer to the user's question using the conversational response as input"], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["example.wav"]}, {"task": "Question Answering", "arguments": ["<node-0>", "Voice assistants are software applications that understand natural language voice commands and complete tasks. They can be found in smartphones, smart speakers, and other devices."]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Question Answering"}], "type": "chain"}
{"id": "26749052", "seed": 284110, "n_tools": 1, "sampled_nodes": [{"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I have an image, example.jpg, and want to modify it so that the background color is changed to white and there is a red circle in the center.", "task_steps": ["Step 1: Modify the image to match given text description."], "task_nodes": [{"task": "Image Editing", "arguments": ["Change the background color to white and add a red circle at the center", "example.jpg"]}], "task_links": [], "type": "single"}
{"id": "22108965", "seed": 810961, "n_tools": 3, "sampled_nodes": [{"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Visual Question Answering", "target": "Translation"}, {"source": "Translation", "target": "Summarization"}], "user_request": "I have an image named 'example.jpg' and a question in English: 'What is the main color of the object in the center?'. Please answer the question, translate the answer into French, and provide a concise summary of the translated answer.", "task_steps": ["1. Answer a visual question based on an image", "2. Translate the answer to another language", "3. Summarize the translated answer"], "task_nodes": [{"task": "Visual Question Answering", "arguments": ["example.jpg", "What is the main color of the object in the center?"]}, {"task": "Translation", "arguments": ["<output of Visual Question Answering>"]}, {"task": "Summarization", "arguments": ["<output of Translation>"]}], "task_links": [{"source": "Visual Question Answering", "target": "Translation"}, {"source": "Translation", "target": "Summarization"}], "type": "chain"}
{"id": "32282113", "seed": 489307, "n_tools": 1, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I am building a chatbot and need a conversational response for the following text prompt: \"What is the difference between machine learning and deep learning?\"", "task_steps": ["Step 1: Generate a conversational response based on a given text prompt"], "task_nodes": [{"task": "Conversational", "arguments": ["What is the difference between machine learning and deep learning?"]}], "task_links": [], "type": "single"}
{"id": "62626281", "seed": 973437, "n_tools": 8, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}, {"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Segmentation", "target": "Image-to-Text"}, {"source": "Image-to-Text", "target": "Text Generation"}, {"source": "Text Generation", "target": "Image Editing"}, {"source": "Image Editing", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Token Classification"}, {"source": "Token Classification", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Automatic Speech Recognition"}], "user_request": "I have an image 'example.jpg' containing a table with some text. I need you to extract and understand the text, edit the image according to understanding of the text, classify the table, tag tokens of the classification result, generate a voiceover based on the tokens, and then transcribe the generated speech back to text.", "task_steps": ["Step 1: Perform image segmentation on the example.jpg", "Step 2: Extract text from the segmented image", "Step 3: Generate new text based on the extracted text", "Step 4: Edit the example.jpg based on the generated text", "Step 5: Perform tabular classification on the edited image", "Step 6: Perform token classification on the classification results", "Step 7: Convert the token classification results to speech", "Step 8: Transcribe the generated speech back to text"], "task_nodes": [{"task": "Image Segmentation", "arguments": ["example.jpg"]}, {"task": "Image-to-Text", "arguments": ["<node-0>"]}, {"task": "Text Generation", "arguments": ["<node-1>"]}, {"task": "Image Editing", "arguments": ["<node-2>", "example.jpg"]}, {"task": "Tabular Classification", "arguments": ["<node-3>"]}, {"task": "Token Classification", "arguments": ["<node-4>"]}, {"task": "Text-to-Speech", "arguments": ["<node-5>"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-6>"]}], "task_links": [{"source": "Image Segmentation", "target": "Image-to-Text"}, {"source": "Image-to-Text", "target": "Text Generation"}, {"source": "Text Generation", "target": "Image Editing"}, {"source": "Image Editing", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Token Classification"}, {"source": "Token Classification", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Automatic Speech Recognition"}], "type": "chain"}
{"id": "25307582", "seed": 356606, "n_tools": 1, "sampled_nodes": [{"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I have an image 'example.jpg' that I would like to modify based on this text description: 'change the background color to white and the main object color to red.'", "task_steps": ["Step 1: Modify the example.jpg image based on the given text description."], "task_nodes": [{"task": "Image Editing", "arguments": ["change the background color to white and the main object color to red.", "example.jpg"]}], "task_links": [], "type": "single"}
{"id": "29908374", "seed": 72206, "n_tools": 3, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Conversational"}, {"source": "Audio Classification", "target": "Visual Question Answering"}], "user_request": "I have an audio file example.wav and an image example.jpg. The audio contains me asking two questions: one that can be answered based on the image, and another question which requires your conversational response.", "task_steps": ["Step 1: Perform Audio Classification on user's audio input.", "Step 2: Generate a conversational response based on the output of the Audio Classification.", "Step 3: Answer user's question based on an uploaded image and the output of the Audio Classification."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Conversational", "arguments": ["<node-0>"]}, {"task": "Visual Question Answering", "arguments": ["example.jpg", "<node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Conversational"}, {"source": "Audio Classification", "target": "Visual Question Answering"}], "type": "dag"}
{"id": "15140716", "seed": 696587, "n_tools": 1, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I want to find the depth estimation of objects in the given image 'example.jpg'.", "task_steps": ["Step 1: Apply depth estimation to the given image"], "task_nodes": [{"task": "Depth Estimation", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "12237871", "seed": 488778, "n_tools": 1, "sampled_nodes": [{"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I want a short summary of the following article: Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.", "task_steps": ["Step 1: Generate a new text summary"], "task_nodes": [{"task": "Text Generation", "arguments": ["I want a short summary of the following article: Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."]}], "task_links": [], "type": "single"}
{"id": "14494890", "seed": 889811, "n_tools": 3, "sampled_nodes": [{"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Text-to-Image", "target": "Object Detection"}, {"source": "Token Classification", "target": "Text-to-Image"}], "user_request": "I have a text describing a historical event: 'On July 20, 1969, Neil Armstrong and Buzz Aldrin landed on the Moon.' I would like to generate an image illustrating this event and identify the objects present in the image.", "task_steps": ["Step 1: Perform token classification on the given text to identify specific entities.", "Step 2: Generate an image based on the identified entities using text-to-image.", "Step 3: Detect objects in the generated image using object detection."], "task_nodes": [{"task": "Object Detection", "arguments": ["<node-1>"]}, {"task": "Text-to-Image", "arguments": ["<node-2>"]}, {"task": "Token Classification", "arguments": ["On July 20, 1969, Neil Armstrong and Buzz Aldrin landed on the Moon."]}], "task_links": [{"source": "Text-to-Image", "target": "Object Detection"}, {"source": "Token Classification", "target": "Text-to-Image"}], "type": "chain"}
{"id": "11660841", "seed": 437791, "n_tools": 1, "sampled_nodes": [{"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I have an image named 'example.jpg' with a red car in it. Can you please change the color of the car to blue based on the text description 'Change the car color to blue'?", "task_steps": ["Step 1: Modify the image based on the given text description"], "task_nodes": [{"task": "Image Editing", "arguments": ["Change the car color to blue", "example.jpg"]}], "task_links": [], "type": "single"}
{"id": "24947174", "seed": 926400, "n_tools": 4, "sampled_nodes": [{"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Segmentation", "target": "Visual Question Answering"}, {"source": "Image-to-Image", "target": "Image Segmentation"}, {"source": "Visual Question Answering", "target": "Token Classification"}], "user_request": "I have an old photo example.jpg that is not clear enough. I would like to enhance the photo, identify objects present in the image, and answer the following question: 'When and where was this photo taken?'. Additionally, extract date and location information from the answer.", "task_steps": ["Step 1: Use Image-to-Image tool to enhance the quality of the example.jpg.", "Step 2: Perform Image Segmentation on the enhanced image to identify and segment objects.", "Step 3: Use Visual Question Answering tool to answer user's question about the segmented image.", "Step 4: Apply Token Classification to the answer obtained in step 3 to recognize dates and locations."], "task_nodes": [{"task": "Image Segmentation", "arguments": ["<node-1>"]}, {"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Token Classification", "arguments": ["<node-3>"]}, {"task": "Visual Question Answering", "arguments": ["<node-0>", "When and where was this photo taken?"]}], "task_links": [{"source": "Image Segmentation", "target": "Visual Question Answering"}, {"source": "Image-to-Image", "target": "Image Segmentation"}, {"source": "Visual Question Answering", "target": "Token Classification"}], "type": "chain"}
{"id": "36779130", "seed": 15626, "n_tools": 1, "sampled_nodes": [{"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}], "sampled_links": [], "user_request": "Create an image of a beautiful sunset with text input: 'A beautiful sunset with purple and orange clouds over the ocean'", "task_steps": ["Step 1: Generate an image from the given text description"], "task_nodes": [{"task": "Text-to-Image", "arguments": ["A beautiful sunset with purple and orange clouds over the ocean"]}], "task_links": [], "type": "single"}
{"id": "12585904", "seed": 831878, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Audio Classification"}, {"source": "Automatic Speech Recognition", "target": "Text-to-Speech"}], "user_request": "I want to transcribe, enhance, and identify my voice commands in the following audio file: 'example.wav'.", "task_steps": ["Step 1: Transcribe the user's voice message using Automatic Speech Recognition.", "Step 2: Convert the transcribed text back into speech using Text-to-Speech.", "Step 3: Enhance the generated speech audio using Audio-to-Audio.", "Step 4: Classify the enhanced audio to identify the user's command or emotion using Audio Classification."], "task_nodes": [{"task": "Audio Classification", "arguments": ["<node-2>"]}, {"task": "Audio-to-Audio", "arguments": ["example.wav"]}, {"task": "Automatic Speech Recognition", "arguments": ["<node-1>"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Audio Classification"}, {"source": "Automatic Speech Recognition", "target": "Text-to-Speech"}], "type": "dag"}
{"id": "47059688", "seed": 487229, "n_tools": 4, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Conversational", "target": "Translation"}, {"source": "Image Editing", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Image Editing"}], "user_request": "I want to know what's in example.jpg. Also, please have a conversation with me on the topic 'Chatbots and AI in daily life' and translate the final conversation in French. Additionally, apply a modification in example.jpg by changing the background to a beach scene.", "task_steps": ["Step 1: Generate a conversational response for the given text, using Conversational tool.", "Step 2: Translate the conversational response text into a different language using the Translation tool.", "Step 3: Answer a question based on the given image and text using the Visual Question Answering tool.", "Step 4: Modify the image according to the given text description using the Image Editing tool."], "task_nodes": [{"task": "Conversational", "arguments": ["Chatbots and AI in daily life"]}, {"task": "Image Editing", "arguments": ["example.jpg", "Change the background to a beach scene."]}, {"task": "Translation", "arguments": ["<node-0>"]}, {"task": "Visual Question Answering", "arguments": ["<node-1>", "What's in the image?"]}], "task_links": [{"source": "Conversational", "target": "Translation"}, {"source": "Image Editing", "target": "Visual Question Answering"}, {"source": "Visual Question Answering", "target": "Image Editing"}], "type": "chain"}
{"id": "29871004", "seed": 894956, "n_tools": 4, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Text-to-Image"}, {"source": "Document Question Answering", "target": "Token Classification"}, {"source": "Text-to-Image", "target": "Document Question Answering"}], "user_request": "I have an audio file 'example.wav' that contains a description of an object. Can you help me visualize the object, answer my question 'What is the color of the object?', and identify any named entities in the answer?", "task_steps": ["Step 1: Transcribe the audio 'example.wav' into text using Automatic Speech Recognition.", "Step 2: Generate an image based on the transcribed text from Step 1 using Text-to-Image.", "Step 3: Answer a question from the user using the generated image from Step 2 and the user's question using Document Question Answering.", "Step 4: Perform token classification on the answer from Step 3 using Token Classification."], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["example.wav"]}, {"task": "Document Question Answering", "arguments": ["<node-2>", "What is the color of the object?"]}, {"task": "Text-to-Image", "arguments": ["<node-0>"]}, {"task": "Token Classification", "arguments": ["<node-1>"]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Text-to-Image"}, {"source": "Document Question Answering", "target": "Token Classification"}, {"source": "Text-to-Image", "target": "Document Question Answering"}], "type": "chain"}
{"id": "46242512", "seed": 358607, "n_tools": 3, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Text-to-Speech", "target": "Audio Classification"}, {"source": "Visual Question Answering", "target": "Audio Classification"}], "user_request": "I have a text 'What a beautiful day!'. I would like to know the emotion expressed in this text after generating its audio. Also, in 'example.jpg', can you please tell me if there are any trees in the image?", "task_steps": ["Step 1: Convert a given text to speech using the Text-to-Speech tool.", "Step 2: Classify the generated audio using the Audio Classification tool.", "Step 3: Answer a question about an image using the Visual Question Answering tool."], "task_nodes": [{"task": "Text-to-Speech", "arguments": ["What a beautiful day!"]}, {"task": "Audio Classification", "arguments": ["<output-of-node-1>"]}, {"task": "Visual Question Answering", "arguments": ["example.jpg", "Are there any trees in the image?"]}], "task_links": [{"source": "Text-to-Speech", "target": "Audio Classification"}, {"source": "Visual Question Answering", "target": "Audio Classification"}], "type": "dag"}
{"id": "98844627", "seed": 867222, "n_tools": 1, "sampled_nodes": [{"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have an image of a park, and I'm curious about how many benches are in the image. Here is the image file: example.jpg. And my question is: How many benches are there in the park?", "task_steps": ["1. Use Visual Question Answering tool to answer a question based on the provided image."], "task_nodes": [{"task": "Visual Question Answering", "arguments": ["example.jpg", "How many benches are there in the park?"]}], "task_links": [], "type": "single"}
{"id": "22067492", "seed": 225508, "n_tools": 1, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I want to estimate the depth of objects in my image 'example.jpg'.", "task_steps": ["Step 1: Estimate the depth of objects in the image."], "task_nodes": [{"task": "Depth Estimation", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "10495901", "seed": 309117, "n_tools": 1, "sampled_nodes": [{"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I would like to have token classification performed on the following text: The quick brown fox jumped over the lazy dog.", "task_steps": ["Step 1: Perform token classification on the given text."], "task_nodes": [{"task": "Token Classification", "arguments": ["The quick brown fox jumped over the lazy dog."]}], "task_links": [], "type": "single"}
{"id": "11190977", "seed": 171997, "n_tools": 4, "sampled_nodes": [{"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}], "sampled_links": [{"source": "Image-to-Image", "target": "Object Detection"}, {"source": "Text Generation", "target": "Text-to-Video"}], "user_request": "I have a text prompt 'A day at the beach' and an image example.jpg. Could you generate a video based on the text prompt, enhance the image, and perform object detection on the enhanced image?", "task_steps": ["Step 1: Generate a text based on the given prompt", "Step 2: Create a video using the generated text", "Step 3: Enhance the example.jpg image", "Step 4: Perform object detection on the enhanced image and identify objects"], "task_nodes": [{"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Object Detection", "arguments": ["<node-0>"]}, {"task": "Text Generation", "arguments": ["A day at the beach"]}, {"task": "Text-to-Video", "arguments": ["<node-2>"]}], "task_links": [{"source": "Image-to-Image", "target": "Object Detection"}, {"source": "Text Generation", "target": "Text-to-Video"}], "type": "dag"}
{"id": "47550074", "seed": 294939, "n_tools": 2, "sampled_nodes": [{"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Text-to-Image", "target": "Visual Question Answering"}], "user_request": "I have a text, 'Grace Hopper was born in New York on December 9, 1906.' I want to generate an image of what is described in this text and then answer the question: 'In which city was Grace Hopper born?'", "task_steps": ["Step 1: Extract entities from input text using Token Classification.", "Step 2: Generate an image based on the extracted entities using Text-to-Image.", "Step 3: Use the generated image along with a question to get an answer using Visual Question Answering."], "task_nodes": [{"task": "Text-to-Image", "arguments": ["Grace Hopper was born in New York on December 9, 1906."]}, {"task": "Visual Question Answering", "arguments": ["<node-0>", "In which city was Grace Hopper born?"]}], "task_links": [{"source": "Text-to-Image", "target": "Visual Question Answering"}], "type": "chain"}
{"id": "12380300", "seed": 33769, "n_tools": 1, "sampled_nodes": [{"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}], "sampled_links": [], "user_request": "Create an image based on the text 'Design a futuristic city skyline'.", "task_steps": ["Step 1: Generate an image based on the given text."], "task_nodes": [{"task": "Text-to-Image", "arguments": ["Design a futuristic city skyline"]}], "task_links": [], "type": "single"}
{"id": "23861167", "seed": 402415, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}], "sampled_links": [{"source": "Audio Classification", "target": "Summarization"}, {"source": "Audio-to-Audio", "target": "Audio Classification"}, {"source": "Summarization", "target": "Text-to-Image"}], "user_request": "I have an audio file, 'example.wav', and I want to enhance its quality, identify its type/genre, generate a summary of the identified information, and create an image representation of that summary.", "task_steps": ["Step 1: Enhance the quality of the input audio file 'example.wav' using Audio-to-Audio tool.", "Step 2: Classify the type/genre of the enhanced audio using Audio Classification tool.", "Step 3: Generate a summary of the classified information using Summarization tool.", "Step 4: Generate an image representation of the summary using Text-to-Image tool."], "task_nodes": [{"task": "Audio Classification", "arguments": ["<node-1>"]}, {"task": "Audio-to-Audio", "arguments": ["example.wav"]}, {"task": "Summarization", "arguments": ["<node-0>"]}, {"task": "Text-to-Image", "arguments": ["<node-2>"]}], "task_links": [{"source": "Audio Classification", "target": "Summarization"}, {"source": "Audio-to-Audio", "target": "Audio Classification"}, {"source": "Summarization", "target": "Text-to-Image"}], "type": "chain"}
{"id": "14571591", "seed": 981652, "n_tools": 4, "sampled_nodes": [{"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}], "sampled_links": [{"source": "Image-to-Image", "target": "Image Segmentation"}, {"source": "Image-to-Image", "target": "Object Detection"}, {"source": "Text-to-Image", "target": "Image-to-Image"}], "user_request": "I have a text prompt 'A beautiful landscape with a river, trees, and mountains.' and I want to generate an image based on this description, enhance the image quality, segment the objects in the image, and detect objects within the image.", "task_steps": ["Step 1: Generate an image from the input text", "Step 2: Enhance the generated image", "Step 3: Segment the enhanced image", "Step 4: Detect objects in the enhanced image"], "task_nodes": [{"task": "Image Segmentation", "arguments": ["<node-1>"]}, {"task": "Image-to-Image", "arguments": ["<node-3>"]}, {"task": "Object Detection", "arguments": ["<node-1>"]}, {"task": "Text-to-Image", "arguments": ["A beautiful landscape with a river, trees, and mountains."]}], "task_links": [{"source": "Image-to-Image", "target": "Image Segmentation"}, {"source": "Image-to-Image", "target": "Object Detection"}, {"source": "Text-to-Image", "target": "Image-to-Image"}], "type": "dag"}
{"id": "63659452", "seed": 490579, "n_tools": 5, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}], "sampled_links": [{"source": "Audio Classification", "target": "Text-to-Video"}, {"source": "Object Detection", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio Classification"}], "user_request": "I have an image (example.jpg) and I want to analyze its depth, detect objects in it, convert the detected objects' descriptions into speech, classify the speech, and generate a video based on the audio classification result.", "task_steps": ["1. Perform depth estimation on the given image.", "2. Detect objects in the depth estimated image.", "3. Convert the detected objects' text descriptions to speech.", "4. Classify the audio based on its content.", "5. Generate a video based on the audio classification result."], "task_nodes": [{"task": "Audio Classification", "arguments": ["<node-2>"]}, {"task": "Depth Estimation", "arguments": ["example.jpg"]}, {"task": "Object Detection", "arguments": ["example.jpg"]}, {"task": "Text-to-Speech", "arguments": ["<node-2>"]}, {"task": "Text-to-Video", "arguments": ["<node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Text-to-Video"}, {"source": "Object Detection", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio Classification"}], "type": "dag"}
{"id": "26483972", "seed": 550025, "n_tools": 3, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Image Classification", "target": "Document Question Answering"}, {"source": "Document Question Answering", "target": "Visual Question Answering"}], "user_request": "I have an image file 'example.jpg' of a document that I want to classify, answer some questions about the classified document, and answer a specific question related to the image.", "task_steps": ["Step 1: Classify the example image.", "Step 2: Ask and answer questions about the classified document image.", "Step 3: Answer a specific question related to the image."], "task_nodes": [{"task": "Image Classification", "arguments": ["example.jpg"]}, {"task": "Document Question Answering", "arguments": ["<node-1>", "What is the main topic of the classified document?"]}, {"task": "Visual Question Answering", "arguments": ["example.jpg", "What is the dominant color in the image?"]}], "task_links": [{"source": "Image Classification", "target": "Document Question Answering"}, {"source": "Document Question Answering", "target": "Visual Question Answering"}], "type": "chain"}
{"id": "21111735", "seed": 861324, "n_tools": 1, "sampled_nodes": [{"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have this sentence: 'The stormy weather caused havoc on our recent camping trip.' Can you help me create a paraphrased version of it?", "task_steps": ["Generate a paraphrased version of a given text"], "task_nodes": [{"task": "Text Generation", "arguments": ["The stormy weather caused havoc on our recent camping trip."]}], "task_links": [], "type": "single"}
{"id": "25166963", "seed": 692487, "n_tools": 1, "sampled_nodes": [{"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [], "user_request": "I want to convert the following text into natural sounding speech: 'Welcome to the world of artificial intelligence. This is an example of text-to-speech conversion.'", "task_steps": ["Generate natural sounding speech from a given text"], "task_nodes": [{"task": "Text-to-Speech", "arguments": ["Welcome to the world of artificial intelligence. This is an example of text-to-speech conversion."]}], "task_links": [], "type": "single"}
{"id": "23304605", "seed": 916149, "n_tools": 1, "sampled_nodes": [{"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}], "sampled_links": [], "user_request": "Create an image that represents the quote 'Stay positive and keep moving forward.'", "task_steps": ["Step 1: Use 'Text-to-Image' tool to generate an image from the input text."], "task_nodes": [{"task": "Text-to-Image", "arguments": ["Stay positive and keep moving forward."]}], "task_links": [], "type": "single"}
{"id": "11286545", "seed": 794628, "n_tools": 1, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}], "sampled_links": [], "user_request": "I need to estimate the depth of objects in the image 'example.jpg'.", "task_steps": ["Apply depth estimation to find the depths of objects in the given image"], "task_nodes": [{"task": "Depth Estimation", "arguments": ["example.jpg"]}], "task_links": [], "type": "single"}
{"id": "28111959", "seed": 162431, "n_tools": 4, "sampled_nodes": [{"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Object Detection", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Video", "input-type": ["text"], "output-type": ["video"]}], "sampled_links": [{"source": "Image Segmentation", "target": "Object Detection"}, {"source": "Image-to-Image", "target": "Image Segmentation"}, {"source": "Object Detection", "target": "Text-to-Video"}], "user_request": "I have an input image named 'example.jpg' and a target image domain in mind. I want my input image to be transformed to match that target image domain. Then, I want my image to be segmented and detect objects inside it. Finally, I would like a video created from the detected objects and following this text: 'The objects detected in the image were:'.", "task_steps": ["Step 1: Convert the user-provided image 'example.jpg' to match the characteristics of a target image domain using the Image-to-Image tool.", "Step 2: Perform Image Segmentation on the output image from the previous step to divide it into segments and map each pixel to an object.", "Step 3: Detect objects in the segmented image using Object Detection to output the images with bounding boxes and labels on detected objects.", "Step 4: Generate a video according to the detected objects and the user-specified text using Text-to-Video tool."], "task_nodes": [{"task": "Image Segmentation", "arguments": ["<node-1>"]}, {"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Object Detection", "arguments": ["<node-0>"]}, {"task": "Text-to-Video", "arguments": ["The objects detected in the image were: <node-2>"]}], "task_links": [{"source": "Image Segmentation", "target": "Object Detection"}, {"source": "Image-to-Image", "target": "Image Segmentation"}, {"source": "Object Detection", "target": "Text-to-Video"}], "type": "chain"}
{"id": "11787134", "seed": 546157, "n_tools": 3, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Visual Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [{"source": "Depth Estimation", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Visual Question Answering"}], "user_request": "I want to know how deep the objects in the example.jpg image are, then transform the image based on the depth information, and finally answer the question: 'What is the dominant color of the object in the center of the transformed image?'", "task_steps": ["Step 1: Estimate the depth of objects in the input image.", "Step 2: Transform the input image using the depth-enhanced image.", "Step 3: Answer a question based on the transformed image."], "task_nodes": [{"task": "Depth Estimation", "arguments": ["example.jpg"]}, {"task": "Image-to-Image", "arguments": ["<node-0>"]}, {"task": "Visual Question Answering", "arguments": ["<node-1>", "What is the dominant color of the object in the center of the transformed image?"]}], "task_links": [{"source": "Depth Estimation", "target": "Image-to-Image"}, {"source": "Image-to-Image", "target": "Visual Question Answering"}], "type": "chain"}
{"id": "27050130", "seed": 182552, "n_tools": 3, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Token Classification", "target": "Document Question Answering"}, {"source": "Translation", "target": "Token Classification"}], "user_request": "I have a document (example.jpg) in Spanish and a text '\u00bfCu\u00e1l es la fecha en el documento? \u00bfD\u00f3nde se llev\u00f3 a cabo el evento?'. Please translate the text into English, perform token classification, and then answer the questions using the document.", "task_steps": ["Step 1: Translate the input text into the desired language", "Step 2: Perform token classification on the translated text", "Step 3: Use the classified tokens as questions, and the input image as the document, to get answers through Document Question Answering"], "task_nodes": [{"task": "Document Question Answering", "arguments": ["example.jpg", "<node-1>"]}, {"task": "Token Classification", "arguments": ["<node-2>"]}, {"task": "Translation", "arguments": ["\u00bfCu\u00e1l es la fecha en el documento? \u00bfD\u00f3nde se llev\u00f3 a cabo el evento?"]}], "task_links": [{"source": "Token Classification", "target": "Document Question Answering"}, {"source": "Translation", "target": "Token Classification"}], "type": "chain"}
{"id": "24554571", "seed": 722214, "n_tools": 3, "sampled_nodes": [{"task": "Automatic Speech Recognition", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Automatic Speech Recognition", "target": "Summarization"}, {"source": "Summarization", "target": "Text Generation"}], "user_request": "I've recorded an audio message and need a creative and summarized response. Here's my audio file: example.wav", "task_steps": ["Step 1: Convert the user's audio message into text using Automatic Speech Recognition.", "Step 2: Generate a creative response to the user's message using Text Generation.", "Step 3: Summarize the creative response using Summarization."], "task_nodes": [{"task": "Automatic Speech Recognition", "arguments": ["example.wav"]}, {"task": "Summarization", "arguments": ["<node-0>"]}, {"task": "Text Generation", "arguments": ["<node-1>"]}], "task_links": [{"source": "Automatic Speech Recognition", "target": "Summarization"}, {"source": "Summarization", "target": "Text Generation"}], "type": "chain"}
{"id": "28423112", "seed": 202492, "n_tools": 3, "sampled_nodes": [{"task": "Audio-to-Audio", "input-type": ["audio"], "output-type": ["audio"]}, {"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Speech", "input-type": ["text"], "output-type": ["audio"]}], "sampled_links": [{"source": "Tabular Classification", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}], "user_request": "I have an image of a table 'example.jpg' that contains important information. I need you to classify the table, convert the classified text content into speech audio, and enhance the generated speech audio for better quality.", "task_steps": ["Step 1: Classify the table image to get the text content.", "Step 2: Convert the classified text content into speech audio.", "Step 3: Enhance the generated speech audio."], "task_nodes": [{"task": "Audio-to-Audio", "arguments": ["<node-2>"]}, {"task": "Tabular Classification", "arguments": ["example.jpg"]}, {"task": "Text-to-Speech", "arguments": ["<node-1>"]}], "task_links": [{"source": "Tabular Classification", "target": "Text-to-Speech"}, {"source": "Text-to-Speech", "target": "Audio-to-Audio"}], "type": "chain"}
{"id": "14844179", "seed": 623111, "n_tools": 5, "sampled_nodes": [{"task": "Depth Estimation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Image-to-Text", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text-to-Image", "input-type": ["text"], "output-type": ["image"]}], "sampled_links": [{"source": "Depth Estimation", "target": "Image-to-Text"}, {"source": "Image Editing", "target": "Depth Estimation"}, {"source": "Image Segmentation", "target": "Image Editing"}, {"source": "Text-to-Image", "target": "Image Segmentation"}], "user_request": "Generate an image with the text 'Example Text' and change the background of the image to the image 'example.jpg'. Then, extract the depth information of the edited image and describe it in text.", "task_steps": ["Generate an image from given text", "Segment the generated image", "Edit the segmented image based on user description", "Estimate depth of the edited image", "Convert the depth image to text"], "task_nodes": [{"task": "Depth Estimation", "arguments": ["<node-1>"]}, {"task": "Image Editing", "arguments": ["example.jpg", "<node-2>"]}, {"task": "Image Segmentation", "arguments": ["<node-4>"]}, {"task": "Image-to-Text", "arguments": ["<node-0>"]}, {"task": "Text-to-Image", "arguments": ["Example Text"]}], "task_links": [{"source": "Depth Estimation", "target": "Image-to-Text"}, {"source": "Image Editing", "target": "Depth Estimation"}, {"source": "Image Segmentation", "target": "Image Editing"}, {"source": "Text-to-Image", "target": "Image Segmentation"}], "type": "chain"}
{"id": "56004472", "seed": 780228, "n_tools": 4, "sampled_nodes": [{"task": "Audio Classification", "input-type": ["audio"], "output-type": ["text"]}, {"task": "Image Editing", "input-type": ["text", "image"], "output-type": ["image"]}, {"task": "Image Segmentation", "input-type": ["image"], "output-type": ["image"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Audio Classification", "target": "Summarization"}, {"source": "Summarization", "target": "Image Editing"}, {"source": "Image Editing", "target": "Image Segmentation"}], "user_request": "I have an interview recording in which I described my favorite place to visit. Please provide me with a modified example.jpg image based on the summarized description of the place and also segment the objects in the resulting image. Here is the audio file: example.wav and the original image: example.jpg.", "task_steps": ["Step 1: Convert user's audio file into text using Audio Classification.", "Step 2: Create a summarized version of the converted text using Summarization.", "Step 3: Modify the given image according to the summarized text using Image Editing.", "Step 4: Apply image-to-image transformation to the edited image using Image-to-Image.", "Step 5: Perform Image Segmentation on the transformed image to separate objects."], "task_nodes": [{"task": "Audio Classification", "arguments": ["example.wav"]}, {"task": "Image Editing", "arguments": ["<node-4>", "example.jpg"]}, {"task": "Image Segmentation", "arguments": ["<node-1>"]}, {"task": "Summarization", "arguments": ["<node-0>"]}], "task_links": [{"source": "Audio Classification", "target": "Summarization"}, {"source": "Summarization", "target": "Image Editing"}, {"source": "Image Editing", "target": "Image Segmentation"}], "type": "chain"}
{"id": "15716091", "seed": 947146, "n_tools": 1, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "I have a document image named 'example.jpg'. I need to know the author mentioned in this document. Please answer the question: Who is the author?", "task_steps": ["Answer a question related to the given document image"], "task_nodes": [{"task": "Document Question Answering", "arguments": ["example.jpg", "Who is the author?"]}], "task_links": [], "type": "single"}
{"id": "12864896", "seed": 359662, "n_tools": 1, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [], "user_request": "User wants the system to generate a relevant, coherent, and knowledgeable conversational response based on the following text prompt: 'What are the health benefits of drinking green tea?'", "task_steps": ["Step 1: Generate a conversational response based on a given text prompt"], "task_nodes": [{"task": "Conversational", "arguments": ["What are the health benefits of drinking green tea?"]}], "task_links": [], "type": "single"}
{"id": "16917664", "seed": 791979, "n_tools": 4, "sampled_nodes": [{"task": "Conversational", "input-type": ["text"], "output-type": ["text"]}, {"task": "Image-to-Image", "input-type": ["image"], "output-type": ["image"]}, {"task": "Tabular Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Text Generation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Conversational", "target": "Text Generation"}, {"source": "Image-to-Image", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Conversational"}], "user_request": "I have a scanned image of a table (example.jpg) with various types of information. I would like to enhance the quality of this image and then automatically classify its content. Based on the classification, please provide me with a conversational response and additional related text.", "task_steps": ["Step 1: Enhance the scanned image of the table", "Step 2: Classify the enhanced table image", "Step 3: Generate a conversational response based on the classification result", "Step 4: Generate additional text based on the conversational response"], "task_nodes": [{"task": "Conversational", "arguments": ["<node-2>"]}, {"task": "Image-to-Image", "arguments": ["example.jpg"]}, {"task": "Tabular Classification", "arguments": ["<node-1>"]}, {"task": "Text Generation", "arguments": ["<node-0>"]}], "task_links": [{"source": "Conversational", "target": "Text Generation"}, {"source": "Image-to-Image", "target": "Tabular Classification"}, {"source": "Tabular Classification", "target": "Conversational"}], "type": "chain"}
{"id": "26051039", "seed": 678759, "n_tools": 2, "sampled_nodes": [{"task": "Image Classification", "input-type": ["image"], "output-type": ["text"]}, {"task": "Sentence Similarity", "input-type": ["text", "text"], "output-type": []}], "sampled_links": [{"source": "Image Classification", "target": "Sentence Similarity"}], "user_request": "I have an image 'example.jpg' and a text 'This is a beautiful sunset'. Please determine the class of the image and compare the similarity with the given text.", "task_steps": ["Step 1: Perform image classification on the given image to determine its class.", "Step 2: Compare the similarity of the obtained class with a given text."], "task_nodes": [{"task": "Image Classification", "arguments": ["example.jpg"]}, {"task": "Sentence Similarity", "arguments": ["<node-0>", "This is a beautiful sunset"]}], "task_links": [{"source": "Image Classification", "target": "Sentence Similarity"}], "type": "chain"}
{"id": "29646562", "seed": 937559, "n_tools": 4, "sampled_nodes": [{"task": "Document Question Answering", "input-type": ["image", "text"], "output-type": ["text"]}, {"task": "Summarization", "input-type": ["text"], "output-type": ["text"]}, {"task": "Token Classification", "input-type": ["text"], "output-type": ["text"]}, {"task": "Translation", "input-type": ["text"], "output-type": ["text"]}], "sampled_links": [{"source": "Translation", "target": "Token Classification"}, {"source": "Token Classification", "target": "Summarization"}, {"source": "Summarization", "target": "Document Question Answering"}], "user_request": "I have a document example.jpg in French, and I want to know the main events described in it. Also, I need the answer in English. Here is a reference text to help: 'Les \u00e9v\u00e9nements importants de l'ann\u00e9e derni\u00e8re incluent la conf\u00e9rence internationale sur le changement climatique et les \u00e9lections nationales.'", "task_steps": ["Step 1: Classify tokens in the given text", "Step 2: Summarize the classified text", "Step 3: Answer the user's question using the summarized text and the document image", "Step 4: Translate the answer into the user's desired language"], "task_nodes": [{"task": "Translation", "arguments": ["Les \u00e9v\u00e9nements importants de l'ann\u00e9e derni\u00e8re incluent la conf\u00e9rence internationale sur le changement climatique et les \u00e9lections nationales."]}, {"task": "Token Classification", "arguments": ["<node-0>"]}, {"task": "Summarization", "arguments": ["<node-1>"]}, {"task": "Document Question Answering", "arguments": ["example.jpg", "<node-2>"]}], "task_links": [{"source": "Translation", "target": "Token Classification"}, {"source": "Token Classification", "target": "Summarization"}, {"source": "Summarization", "target": "Document Question Answering"}], "type": "chain"}
